{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source code - https://github.com/iwiszhou/ML1010-final-project\n",
    "\n",
    "This is a Yelp data-set. I would use this data-set to do a sentiment analysis.\n",
    "I would build a model to predict the review either positive or negative.\n",
    "This is a big data-set. Firstly, I would try to extra the review data and create a simple data-set,\n",
    "which only contain Review & Rating. After that, I would create a new column which is Class.\n",
    "Class column is either Positive or Negative. If Rating is grater than 3, I would mark Class to Positive. Otherwise,\n",
    "Negative. If I have more time at the end, I would introduce one more value to Class column which is Neutral ( when\n",
    "Rating is equal to 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/iwiszhou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from file\n",
    "NOTE - the data-set is too big. I have already to several time, my computer crash. So that, I would start with first 10000 rows. I would increase the data-set size when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/iwiszhou/Documents/Machine Learning/ML1010/ML1010-final-project/yelp_dataset/review.json\"\n",
    "rowCount = 0\n",
    "rowLimit = 10000\n",
    "df = []\n",
    "with open(filename, 'r') as f:\n",
    "    for line in f:\n",
    "        df.append(json.loads(line))\n",
    "        rowCount = rowCount + 1\n",
    "        if rowCount > rowLimit:\n",
    "            break\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  \\\n",
      "0  Q1sbwvVQXV2734tPgoKj4Q  hG7b0MtEbXx5QzbzE6C_VA  ujmEBvifdJM6h6RLv4wQIg   \n",
      "1  GJXCdrto3ASJOqKeVWPi6Q  yXQM5uF2jS6es16SJzNHfg  NZnhc2sEQy3RmzKTZnqtwQ   \n",
      "2  2TzJjDVDEuAW6MR5Vuc1ug  n6-Gk65cPZL6Uz8qRm3NYw  WTqjgwHlXbSFevF32_DJVw   \n",
      "3  yi0R0Ugj_xUx_Nek0-_Qig  dacAIZ6fTM6mqwW5uxkskg  ikCg8xy5JIg_NGPx-MSIDA   \n",
      "4  11a8sVPMUFtaC7_ABRkmtw  ssoyf2_x0EQMed6fgHeMyQ  b1b1eb3uo-w561D0ZfCEiQ   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0    1.0       6      1     0   \n",
      "1    5.0       0      0     0   \n",
      "2    5.0       3      0     0   \n",
      "3    5.0       0      0     0   \n",
      "4    1.0       7      0     0   \n",
      "\n",
      "                                                text                 date  \n",
      "0  Total bill for this horrible service? Over $8G...  2013-05-07 04:34:36  \n",
      "1  I *adore* Travis at the Hard Rock's new Kelly ...  2017-01-14 21:30:33  \n",
      "2  I have to say that this office really has it t...  2016-11-09 20:09:03  \n",
      "3  Went in for a lunch. Steak sandwich was delici...  2018-01-09 20:56:38  \n",
      "4  Today was my second out of three sessions I ha...  2018-01-30 23:07:38  \n",
      "10001\n",
      "Index(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny',\n",
      "       'cool', 'text', 'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check data-set\n",
    "print(df.head())\n",
    "\n",
    "# Check number of rows\n",
    "count_row = df.shape[0]\n",
    "print(count_row)\n",
    "\n",
    "# List all columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class column\n",
    "def get_class_label_value(row):\n",
    "    if row[\"stars\"] >= 3:\n",
    "        return \"Positive\"\n",
    "    return \"Negative\"\n",
    "\n",
    "\n",
    "df[\"class\"] = df.apply(lambda row: get_class_label_value(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                                               text     class\n",
      "0  ujmEBvifdJM6h6RLv4wQIg  Total bill for this horrible service? Over $8G...  Negative\n",
      "1  NZnhc2sEQy3RmzKTZnqtwQ  I *adore* Travis at the Hard Rock's new Kelly ...  Positive\n",
      "2  WTqjgwHlXbSFevF32_DJVw  I have to say that this office really has it t...  Positive\n",
      "3  ikCg8xy5JIg_NGPx-MSIDA  Went in for a lunch. Steak sandwich was delici...  Positive\n",
      "4  b1b1eb3uo-w561D0ZfCEiQ  Today was my second out of three sessions I ha...  Negative\n",
      "10001\n",
      "Index(['business_id', 'text', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create new data frame\n",
    "filterDf = df[['business_id', 'text', 'class']]\n",
    "print(filterDf.head().to_string())\n",
    "print(filterDf.shape[0])\n",
    "print(filterDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre-processing\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwiszhou/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 business_id                                               text     class                                         clean_text\n",
      "6252  cSIt_NA2mQAmL_sk7f7TbA  I've been anticipating the opening of Thai Exp...  Positive  ive anticipating opening thai express quite so...\n",
      "4684  GvKx1QL6XLyMZnWZun1DPQ  A great stop in Waxhaw. My wife and I frequent...  Positive  great stop waxhaw wife frequently come lazy sa...\n",
      "business_id    object\n",
      "text           object\n",
      "class          object\n",
      "clean_text     object\n",
      "dtype: object\n",
      "10001\n",
      "             count unique                                                top  freq\n",
      "business_id  10001   4619                             Wxxvi3LZbHNIDwJ-ZimtnA    79\n",
      "text         10001  10001  I have no idea how the food tastes. We were he...     1\n",
      "class        10001      2                                           Positive  7672\n",
      "clean_text   10001  10001  man went brunch time 11am line looked long ( s...     1\n"
     ]
    }
   ],
   "source": [
    "# Create a clean text column\n",
    "\n",
    "def get_clean_text_value(row):\n",
    "    if row[\"text\"]:\n",
    "        return normalize_corpus(row[\"text\"])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "filterDf[\"clean_text\"] = df.apply(lambda row: get_clean_text_value(row), axis=1)\n",
    "\n",
    "# Exploring Column Summaries\n",
    "print(filterDf.sample(2, random_state=42).to_string())\n",
    "print(filterDf.dtypes)\n",
    "print(len(filterDf))\n",
    "print(filterDf.describe(include=np.object).transpose().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to database\n",
    "con = sqlite3.connect('yelp.db')\n",
    "filterDf.to_sql(\"filter_reviews\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
